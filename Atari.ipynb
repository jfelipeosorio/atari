{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atari.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7S0W8ek8Ax_5",
        "bG2I7nyf3gGt",
        "ffmVFPiH3gGu",
        "J5YFq6oj3gGz",
        "17o3IYMI3gG4",
        "U4P_84f53gG8",
        "39PfsbP93gHA",
        "KXRVpzg23gHG",
        "8H-g16zS3gHL",
        "nYeCKj-T3gHN",
        "oZ4DfWLM3gHP",
        "illmIEdhdRsc",
        "Qwt96xJ3dRsc",
        "CzikqWmmdRsg",
        "OMTmcndVdRsk",
        "RpOFkTOkRZw6",
        "D3cGyt7ORZxA",
        "gKTGgtDuRZxG",
        "PnuVL9TyRZxN",
        "wMYP1-GWRZxQ",
        "cOAn6QAhRZxX",
        "AWlMpKl8RZxc",
        "9MZkYjOWRZxd",
        "374EOXq2RZxf",
        "9Z6YVCODRZxg",
        "71CzJtj-RZxj",
        "-nzL6aQTRZxm",
        "6CEW5GYWRZxp",
        "WrYhKvsDRZxq",
        "JAGLrw1-RZxt"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanosoriodata/atari/blob/master/Atari.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0dmSa_c8wnG",
        "colab_type": "text"
      },
      "source": [
        "Hecho por *Juan Felipe Osorio Ramírez* en el curso de Minería de Datos en la Universidad Nacional de Colombia, Sede Bogotá.\n",
        "\n",
        "El contenido (imágenes y teoría) se toma de las siguientes referencias y tiene con último fin la **academia**:\n",
        "1. Saito, S., Wenzhuo, Y., & Shanmugamani, R. (2018). Python Reinforcement Learning Projects: Eight hands-on projects exploring reinforcement learning algorithms using TensorFlow. Packt Publishing Ltd.\n",
        "\n",
        "2. Evans, L. C. (1983). An introduction to mathematical optimal control theory version 0.2. Lecture notes available at http://math.berkeley.edu/~evans/control.course.pdf .\n",
        "\n",
        "3. Sutton, R. S., & Barto, A. G. (1998). Introduction to reinforcement learning (Vol. 135). Cambridge: MIT press.\n",
        "\n",
        "4. Balakrishnan, K. (2020). TensorFlow Reinforcement Learning Quick Start Guide. Packt Publishing Ltd. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZM-whkq6_-l",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# ATARI\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P30EjumneIFl",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Atari_logo.svg/1280px-Atari_logo.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odNaDE1zyrL2",
        "colab_type": "text"
      },
      "source": [
        "Este cuaderno reproduce un proyecto de Aprendizaje Reforzado cuyo alcance es:\n",
        "- Implementar un emulador del juego Atari usando `gym`.\n",
        "- Explorar el preprocesamiento de datos en tareas de este tipo de aprendizaje, en este caso para el juego Atari.\n",
        "- Explorar el algoritmo Q-learning.\n",
        "- Implementar DQN usando TensorFlow y visualizar el entrenamiento.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYQiEOHxAVAK",
        "colab_type": "text"
      },
      "source": [
        "## Intuición y Matemáticas detrás de escenas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4vQR2qc140M",
        "colab_type": "text"
      },
      "source": [
        "### ¿Qué es el Aprendizaje Reforzado?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmq6FAGrxuUe",
        "colab_type": "text"
      },
      "source": [
        "En este tipo de machine learning, se tiene un **agente** que se refiere al algoritmo/modelo que aprende una tarea específica.\n",
        "\n",
        "El agente aprende principalmente al recibir una **señal de recompensa**, que es un escalar que indica que tan bien el agente está realizando la tarea.\n",
        "\n",
        "Suponga que tenemos un agente cuya tarea es controlar el movimiento de caminar de un robot. El agente recibirá una recompensa positiva si logra hacer caminar el robot al destino fijado y recompensa negativa si se cae o no camina en dirección del destino.\n",
        "\n",
        "Además, estas señales de recompensa se retornan como consecuencia de una serie de **acciones** que el agente realiza; esto a diferencia de como se retribuye la señal en un modelo de aprendizaje supervisado, en el cual se hace inmediatamente se entrena el modelo. Las acciones son simplemente esas opciones disponibles que tiene el agente para hacer en el **ambiente**. El ambiente se refiere al mundo en el que el agente vive y se encarga principalmente de retornar las señales de recompensa al agente. Las acciones del agente normalmente están condicionadas a lo que el agente percibe del ambiente. Lo que el agente percibe se concibe como la **observación** o el **estado** del ambiente. \n",
        "\n",
        "Nota: Lo que distingue el aprendizaje reforzado de otros paradigmas es que las acciones que realiza el agente pueden alterar el ambiente y sus respuestas subsecuentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tkjbBvZ2O1C",
        "colab_type": "text"
      },
      "source": [
        "#### Ejemplo: Space Invaders de Atari"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9HMIoQD2Ut_",
        "colab_type": "text"
      },
      "source": [
        "En este caso el agente tiene como tarea jugar **Breakout**, el juego de Arcade Atari 2600. El ambiente es el juego como tal y la lógica que este tiene en sus especificaciones. Durante el juego, el agente consulta al ambiente para hacer una observación (que es equivalente a tener un estado). Aquí la observación es un array de tamaño $(210,160,3)$, que coincide  con la pantalla del juego que muestra la barra del agente, la pelota, los bloques a romper y el puntaje. Basado en esta observación, el agente realiza algunas acciones, que pueden incluir el moverse a la izquierda, derecha o quedarse quieto. El ambiente recibe la acción del agente como *input* y hace los respectivos *updates* al estado.\n",
        "\n",
        "Por ejemplo, si la pelota toca un bloque, se remueve del juego. Si el agente decide moverse a la izquierda, el juego hará el update de cambiar las coordenadas de acuerdo a esto. Este proceso se repite hasta que se alcanza **estado terminal**, un estado que representa el final de una sucesión. En Breakout, el estado terminal se alcanza cuando la nave del agente es destruida, y el juego subsecuentemente retorna el puntaje que lleva, que se calcula con base en el número de naves enemigas que se destruyeron.\n",
        "\n",
        "Nota: Algunos ambientes no tienen estados terminales, como el mercado de acciones. Estos siguen andando mientras existan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsfJ7tC95ueQ",
        "colab_type": "text"
      },
      "source": [
        "#### Resumen de términos  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRVC7Irm53kl",
        "colab_type": "text"
      },
      "source": [
        "Término | Descripción | Ejemplos\n",
        "--- | --- | ---\n",
        "Agente | Un algoritmo/modelo que aprende una tarea específica. | Carros Self-Driving, Robots que caminan, **jugador de video juegos**. \n",
        "Ambiente | El mundo en el que el agente actúa. Es responsable de controlar los que el agente percibe y provee la retroalimentación sobre que tan bien el agente realiza la tarea. | El camino sobre el que anda el carro, **un video juego**, el mercado de las acciones.\n",
        "Acción | La decisión que toma el agente en un ambiente, usualmente depende de lo que el agente percibe | Dirigir un carro, comprar o vender una acción, **disparar un laser de la nave que el agente controla**.\n",
        "Señal de recompensa| Un escalar que indica que tan bien el agente está realizando una tarea.| **El puntaje de Space Invaders**, ROI de una compra de acción, distancia recorrida por un robot que intenta caminar.\n",
        "Observación/Estado| Una descripción de el ambiente tal como la percibe el agente | Video desde una cámara, **la pantalla del juego**, estadísticas del mercado de acciones.\n",
        "Estado terminal|Un estado en el que el agente no puede realizar más acciones.| Llegar al final de un laberinto, **la nave del agente en Space Invaders es destruida**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1WhjnhSEwS_",
        "colab_type": "text"
      },
      "source": [
        "Formalmente, miremos que sucede en el tiempo $t$ con un agente $P$ y un ambiente $E$:\n",
        "1. $P$ consulta una observación $s_t$ de $E$. \n",
        "2. $P$ decide tomar una acción $a_t$ basada en la observación $s_t$.  \n",
        "3. $E$ recibe $a_t$ y retorna una recompensa $r_t$ basado en la acción.\n",
        "4. $P$ recibe $r_t$.\n",
        "5. $E$ actualiza $s_t$ a $s_{t+1}$  basado en $a_t$  y otros factores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ5jG0mYH6rT",
        "colab_type": "text"
      },
      "source": [
        "Ahora, ¿De qué manera el ambiente calcula $r_t$ y $s_{t+1}$?\n",
        "\n",
        "Para esto el ambiente usualmente tiene su propio algoritmo que calcula estos valores basado en numerosos *inputs/factors*, incluyendo la acción que el agente realiza.\n",
        "A continuación, vamos a discutir en mayor detalle el mayor protagonista de cada problema de aprendizaje reforzado- el agente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u4oCx-kLSvI",
        "colab_type": "text"
      },
      "source": [
        "#### El Agente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1aqzaYcLxIb",
        "colab_type": "text"
      },
      "source": [
        "El objetivo del agente de aprendizaje reforzado es aprender a desempeñar una tarea bien en un ambiente. Matemáticamente, esto significa que queremos maximizar la recompensa acumulada $R$, que se expresa así:\n",
        "\n",
        "$R= r_0+\\gamma^1r_1+\\cdots+\\gamma^tr_t$\n",
        "\n",
        "En donde simplemente calculamos una suma ponderada de la recompensa recibida en cada tiempo $t$. $\\gamma$ se llama un **factor de descuento**, y es un escalar que toma valores entre $0$ y $1$. La idea detrás de este factor es tal que a mayor tiempo transcurrido tiene la recompensa, menor valor tiene en R. Esto refleja también la perspectiva en las recompensas del mundo real, en la que preferimos recibir $100.000$ COP ahora *vs.* en un año. Ya que el valor de la recompensa puede ser mayor cuando estamos más cerca del presente. \n",
        "\n",
        "Debido a que la mecánica del ambiente no es completamente observable para el agente, este último debe ganar información al tomar acciones y observar como el ambiente reacciona a estas. Y de esta manera los humanos aprender a desempeñar sus tareas a lo largo de la vida.\n",
        "\n",
        "Supongamos que estamos aprendiendo a jugar ajedrez. Si bien no tenemos todos los movimiento posibles guardados en memoria o no sabemos como jugará nuestro oponente, podemos mejorar nuestra competencia con el tiempo. En particular, podemos llegar a ser competentes en lo siguiente: \n",
        "\n",
        "- Aprender como reaccionar a un movimiento que hace nuestro oponente.\n",
        "- Evaluar que tan buena es nuestra posición para ganar el juego.\n",
        "- Predecir que hará nuestro oponente en la siguiente jugada y usar esto para decidir nuestro movimienot actual.\n",
        "- Entender como jugarían los jugadores en general en una situación en la que nos encontramos en el momento.\n",
        "\n",
        "De hecho, los agentes de aprendizaje reforzado pueden aprender a hacer cosas similares. En particular, un agente está compuesto de múltiples funciones y modelos para asistir su toma de decisión. Existen tres componentes que los agentes pueden tener: \n",
        "- Una **política**\n",
        "- Una **función de valor**\n",
        "- Un **modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjvLYZEISzHN",
        "colab_type": "text"
      },
      "source": [
        "#### La *política* del *agente*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYZ4piW-TYbT",
        "colab_type": "text"
      },
      "source": [
        "Una **política** es un algoritmo o un conjunto de reglas que describe como un agente toma sus decisiones. Un ejemplo de una, puede ser la estrategia que un inversionista usa para invertir en sus acciones, donde este compra una acción cuando los precios bajan y la vende cuando los precios suben.\n",
        "\n",
        "Formalmente, una política es una función, denotada por $\\pi$ que mapea un estado $s_t$ a una acción $a_t$:\n",
        "\n",
        "$\\pi(s_t)=a_t$\n",
        "\n",
        "Lo cuál significa que el agente decide su acción tomando en cuenta su estado actual. Esta función puede representar muchas cosas, en la medida en que reciba un estado como input y una acción como output, sea una tabla, un grafo, o un clasificador de machine learning.\n",
        "\n",
        "Siendo estrictos en la manera que definimos la política, esta resulta ser **determinística** y no en todas las aplicaciones es así. Es por esto que aparece una manera más general de definir la política y es de manera **estocástica** donde esta tiene como output una distribución de probabilidad sobre el conjunto de acciones posibles en un estado:\n",
        "\n",
        "$\\pi(a_t|s_t)=P(a_t|s_t)$\n",
        "\n",
        "donde $\\pi(a_t| s_t)$ es un vector de probabilidades normalizado sobre el conjunto de posibles acciones dado un estado. Aplicando al ejemplo de Atari este concepto de política, veamos la siguiente imagen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBVV5pjotU5N",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "from google.colab import files\n",
        "from IPython.display import Image\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxLQDHjYts7K",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "d8b31590-d5da-4707-f1b5-acd67b616c43"
      },
      "source": [
        "#@title\n",
        "Image('eb108444-97b9-4201-9aff-49ced33c3309.jpg', width = 600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/jpeg": {
              "width": 600
            }
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3oLIem3lDQO",
        "colab_type": "text"
      },
      "source": [
        "Imagen: Como la política mapea el estado del juego (la pantalla) a las acciones (probabilidades)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5aYMI9IS-uB",
        "colab_type": "text"
      },
      "source": [
        "#### La *función de valor* del agente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlRjH-jBmC0l",
        "colab_type": "text"
      },
      "source": [
        "El segundo componente que un agente puede tener es la **función de valor**. Como se mencionó en la introducción, es útil evaluar la posición, si es buena o mala, en un estado dado. En una partida de ajedrez, a un jugador le gustaría saber la verosimilitud de que va a ganar dado un estado del tablero. Un agente navegando un laberinto le gustaría saber que tan cerca está de llegar a su destino. La idea es que la función de valor quiere satisfacer los propósitos anteriores, ya que *predice el valor esperado de recompensa que un agente recibiría en un estado dado*. En otras palabras, mide que tan deseable es para el agente, su estado actual.\n",
        "\n",
        "Formalmente, la función de valor toma un estado y una política como input y retorna un valor escalar representando la esperanza de la recompensa acumulada:\n",
        "\n",
        "$v(s,\\pi)= E[R|s,\\pi]=E[r_0+\\gamma^1r_1+\\cdots+\\gamma^tr_t|s,\\pi]$\n",
        "\n",
        "Ahora, ¿De qué manera esta función ayuda al agente a desempeñar una tarea bien, a parte de informar sobre que tan deseable es estar en un estado dado? Como veremos luego, las funciones de valor juegan un papel importante en predecir que tan bueno será el tomar una serie de acciones antes de que sean tomadas por el agente. Esto es similar a que los jugadores de ajedrez se imaginen qué tan bien una secuencia de acciones futuras funcionará para mejorar sus posibilidades de ganar. Para esto, el agente también necesita tener un entendimiento de como el ambiente opera. Y este entendimiento, resulta en el tercer componente de un agente que es, **el modelo**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UspD7gneTECy",
        "colab_type": "text"
      },
      "source": [
        "#### El *modelo* del agente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmdifE3wsBRV",
        "colab_type": "text"
      },
      "source": [
        "Anteriormente, se discutió como el agente no conoce completamente el ambiente. En otras palabras, el agente usualmente no tiene una idea de como se ve internamente el algoritmo completo del ambiente.\n",
        "\n",
        "El agente necesita interactuar con el ambiente para ganar información y aprender como maximizar el valor esperado de la recompensar acumulada. Sin embargo, es posible para el agente tener una réplica interna, o un modelo, de el ambiente. El agente puede usar el modelo para predecir de qué manera el ambiente reaccionaría a alguna acción en un estado dado. Un modelo en el mercado de las acciones, por ejemplo, tiene la tarea de predecir como los precios serán en un futuro. Si el modelo es preciso, el agente puede entonces usar su función de valor para evaluar que tan deseable es el futuro. \n",
        "\n",
        "Formalmente, el modelo puede ser representado por una función $M$ que calcula la probabilidad del siguiente estado dado el estado actual y un acción: (MONTENEGRO?)\n",
        "\n",
        "$M(a_t,s_t)=P(s_{t+1}|s_t,a_t)$\n",
        "\n",
        "En otro escenarios, el modelo del ambiente puede ser usado para enumerar posibles estados futuros. Esto es común en juegos basados por turno, tales como el ajedrez o triki, donde las reglas y alcance de las posibles acciones están claramente definidas. Normalmente se hacen árboles de para ilustrar estas posibles sucesiones de acciones y estados de juegos basados en turno:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoVOi3rtyrro",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "HxCadGjWyj29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "acdd5581-9076-4313-9dd8-40989056d93f"
      },
      "source": [
        "#@title\n",
        "Image('4466b8eb-0b71-414e-837f-49b0109e738f.jpg', width = 600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/jpeg": {
              "width": 600
            }
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZGxlsTVytR1",
        "colab_type": "text"
      },
      "source": [
        "Imagen: Un modelo usando su valor de función para evaluar sus posibles movimientos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMiWAmtx0Vxw",
        "colab_type": "text"
      },
      "source": [
        "En el ejemplo anterior del juego triki, $M(s_t,a_t)$ denota los posibles estados que al tomar una acción $a_t$ (representada en la imagen como un círculo azul con rayas dentro) podría tomar en un estado dado $s_t$. Más aún, podemos calcular el valor de cada estado usando el valor de la *función de valor*. Los estados intermedios o de abajo en la imagen llevarían a obtener un valor alto ya que el agente estaría a un paso de ganar, caso contrario al caso de arriba ya que aquí se debe preocupar de que el oponente gane.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XeeF2w-4ruc",
        "colab_type": "text"
      },
      "source": [
        "#### Resumen de términos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFkry3Xl41K7",
        "colab_type": "text"
      },
      "source": [
        "Término | Descripción | Output\n",
        "--- | --- | ---\n",
        "Política | Algoritmo/función que retorna decisiones que el agente toma. | Un escalar único (decisión) (política determinística) o un vector de probabilidades sobre posibles acciones (política estocástica)\n",
        "Función de Valor |  Función que describe que tan bueno o malo es un estado dado. | Un valor escalar que representa el valor esperado de la recompensa acumulada.\n",
        "Modelo | Una representación del ambiente que tiene el agente, que predice como reaccionará el ambiente a las acciones que el agente realiza.| La probabilidad del próximo estado dados una acción y el estado actual, o una enumeración de posibles estados dadas las reglas del ambiente.\n",
        "\n",
        "Finalmente, usaremos estos conceptos para aprender uno de los marcos conceptuales fundamentales en aprendizaje reforzado: los **Procesos de Decisión de Markov**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYGfJ6m6AJHh",
        "colab_type": "text"
      },
      "source": [
        "#### Procesos de Decisión de Markov (PDM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAsXm35YA5f7",
        "colab_type": "text"
      },
      "source": [
        "Un **proceso de decisión de Markov** es un marco usado para representar el **ambiente** en un problema de aprendizaje reforzado. Este se puede representar gráficamente mediante un grafo con arcos dirigidos. Cada nodo representa un posible estado en el ambiente, y cada arco apuntando a un estado representa la acción que se puede tomar en el estado actual. \n",
        "\n",
        ">*Formalizaremos el problema del aprendizaje reforzado usando ideas de la Teoría de Sistemas Dinámicos, específicamente, el **control optimal de un proceso de decisión de Markov parcialmente-conocido**.*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWcz2Vcc1ggy",
        "colab_type": "text"
      },
      "source": [
        "Consideremos el siguiente ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "t6Zfn8fu0MmQ",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "fRKex-Of0Mm-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "4186e4cd-eced-4490-8a71-d77340a44d85"
      },
      "source": [
        "#@title\n",
        "Image('ff232de9-03c2-4ca7-8160-6e9320b6a0c6.jpg', width = 600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/jpeg": {
              "width": 600
            }
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy7G5BvlcAPY",
        "colab_type": "text"
      },
      "source": [
        "Imagen: Un Proceso de Decisión de Markov."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-b6ES_ZclHs",
        "colab_type": "text"
      },
      "source": [
        "El anterior PDM representa una jornada típica de un programador en un día. Cada círuclo representa un estado particular en el cual el programador puede estar, y en particular el estado azul (Wake up) es estado inicial (o el estado en $t=0$ que está el agente), y el estado naranja (Publish Code) denota el estado terminal. Cada estado tiene una recompensa que está asociada, y entre más alta sea, más deseable será.\n",
        "\n",
        "Además una representación del grafo del ejemplo es su **matriz de adyacencia**:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxNNibNqf4H7",
        "colab_type": "text"
      },
      "source": [
        "State/Action | Wake Up | Netflix | Code and Debug | Nap | Deploy | Sleep\n",
        "--- | --- | --- | --- | --- | --- | ---\n",
        "Wake Up | N/A | -2 | -3 | 0 | N/A | N/A\n",
        "Netflix | N/A | -2 | N/A | N/A | N/A | N/A\n",
        "Code and Debug | N/A | N/A | N/A | 1 | 10 | 3\n",
        "Nap | 0 | N/A | N/A | N/A | N/A | N/A\n",
        "Deploy | N/A | N/A | N/A | N/A | N/A | 3\n",
        "Sleep | N/A | N/A | N/A | N/A | N/A | N/A\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imIPes9wCVYK",
        "colab_type": "text"
      },
      "source": [
        "La columna de la izquierda representa los posibles estados y la primera fila representan las posibles acciones. N/A siginifa que la acción no se puede realizar estan en el estado dado. Este sistema básicamente representa las decisiones que un programador puede realizar en un día.\n",
        "\n",
        "Cuando el programador se levanta (*Wake up*), este puede decidir ir a trabajar (*Code and debug the code*) o ir a ver películas (*Netflix*). Nótese que la recompensa por ver Netflix es más alta que ir a trabajar. Para el programador en cuestión, ver Netflix resulta ser una actividad mejor recompensada, mientras que hacer código y debugging de este (que se espera no sea la misma idea del lector). Sin embargo, ambas acciones nos llevan a obtener recompensas negativas, pero recordemos que nuestro objetivo es maximizar la recompensa acumulada. Si el programador decide ver Netflix, se quedaría atrapado en un bucle infinito, que a la final termina debilitando la recompensa acumulada. Por otro lado, más estados con mejor recompensa estarán disponibles para el programador si se decide por trabajar.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R171E7y0IYMS",
        "colab_type": "text"
      },
      "source": [
        "Examinemos las posibles trayectorias, que son sucesiones de acciones que el programador puede tomar:\n",
        "- Wake Up | Netflix | Netflix | ...\n",
        "- Wake Up | Code and Debug | Nap | Wake Up | Code and Debug | Nap | ...\n",
        "- Wake Up | Code and Debug | Sleep\n",
        "- Wake Up | Code and Debug | Deploy | Sleep\n",
        "\n",
        "La primera y segunda trayectoria representan bucles infinitos. Calculemos la recompensa acumulada para cada una, donde hacemos $\\gamma = 0.9$:\n",
        "- $R = 0+0.9\\times(-2)+0.9^2\\times(-2)+0.9^3\\times(-2)\\cdots<0$\n",
        "- $R = 0+0.9\\times(-3)+0.9^2\\times(1)+0.9^3\\times(0)+0.9^4\\times(-3)+0.9^5\\times(1)\\cdots<0 $\n",
        "- $R = 0+0.9\\times(-3)+0.9^2\\times(3)=-0.27$\n",
        "- $R = 0+0.9\\times(-3)+0.9^2\\times(10)+0.9^3\\times(3)=7.587$\n",
        "\n",
        "Podemos ver que para la primera y segunda trayectoria, a pesar de no tener un estado terminal, nunca tendremos recompensas positivas. La cuarta trayectoria nos brinda la recompensa acumulada más alta.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VESiC1W2NIra",
        "colab_type": "text"
      },
      "source": [
        "Lo que hemos calculado entonces son las funciones de valor para cuatros políticas que un programador puede tomar en un día. Recordemos que la función de valor es la esperanza de la recompensa acumulada empezando por un estado dado y siguiente un política. \n",
        "\n",
        "Hemos observado cuatro posibles políticas y evaluado como cada una de ellas nos lleva a obtener una recompensa acumulada distinta, ejercicio conocido como **evaluación de política**.\n",
        "\n",
        "Más aún, las ecuaciones que hemos usado para calcular las recompensas esperadas son conocidas como **Ecuaciones de esperanza de Bellman**. Las ecuaciones de Bellman forman un conjunto de ecuaciones usadas para evaluar y mejorar políticas y funciones de valor para finalmente ayudar a un agente a desempeñar de mejor manera una tarea. \n",
        "\n",
        "Para ver más sobre estas ecuaciones fundamentales en el estudio de aprendizaje reforzado ver la referencia [3], al inicio de este cuaderno.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSX1lIH8PeNw",
        "colab_type": "text"
      },
      "source": [
        "#### ¿Qué sigue ahora?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g6BwRi_PjWE",
        "colab_type": "text"
      },
      "source": [
        "Ahora que hemos pasado por términos y conceptos clave de aprendizaje reforzado, el lector se preguntará por cómo enseñar a un agente de aprendizaje reforzado a maximizar su recompensa, o en otras palabras, tomando el ejemplo del PDM del programador, que sepa que la cuarta trayectoria es la mejor. \n",
        "\n",
        "Para nuestro proyecto con ATARI trabajaremos en la solución a este interrogante usando **Aprendizaje Profundo**. Para lo cuál haremos una sección introduciendo el tema. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRRYttZuRCvs",
        "colab_type": "text"
      },
      "source": [
        "### ¿Qué es el Aprendizaje Profundo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSeJfqYXR0_G",
        "colab_type": "text"
      },
      "source": [
        "Este tipo de aprendizaje se ha convertido muy popular en los campos de estadística, ciencias de la computación y el machine learning. Gracias al aumento de recursos de máquina y datos, los algoritmos en este campo han sobrepasado los resultados de sus pasados estados del arte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfYRibxwAi--",
        "colab_type": "text"
      },
      "source": [
        "## Infrastructura y Dependecias "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S0W8ek8Ax_5",
        "colab_type": "text"
      },
      "source": [
        "## Aprendizaje de Máquina en Acción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG2I7nyf3gGt",
        "colab_type": "text"
      },
      "source": [
        "### Entendamos el archivo model.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffmVFPiH3gGu",
        "colab_type": "text"
      },
      "source": [
        "#### Importamos los paquetes requeridos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YpqJGec3gGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5YFq6oj3gGz",
        "colab_type": "text"
      },
      "source": [
        "#### Escogemos una red pequeña (smaller) o grande (bigger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cudb1dS73gG0",
        "colab_type": "text"
      },
      "source": [
        "Usaremos dos arquitecturas de red neuronal, una llamda `bigger` y la otra llamada `smaller`. Usaremos la red `bigger` por ahora; si se quiere usar la otra opción para comparar rendimientos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ys5_Ypn3gG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NET = 'bigger' # 'smaller'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17o3IYMI3gG4",
        "colab_type": "text"
      },
      "source": [
        "#### Escogemos la función de pérdida (L2 o Huber)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZTX70Pr3gG4",
        "colab_type": "text"
      },
      "source": [
        "Para la función de pérdida del algoritmo Q-learning, podremos usar entre la pérdida `L2` o la de `huber`. Ambas opciones serán usadas en el resto del proyecto. Por ahora nos quedamos con `huber`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJSNzrtV3gG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOSS = 'huber' # 'L2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4P_84f53gG8",
        "colab_type": "text"
      },
      "source": [
        "#### Definimos los pesos de inicialización de la red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvh5mT633gG8",
        "colab_type": "text"
      },
      "source": [
        "Especificaremos un inicializador de pesos para los pesos de la red. `tf.variance_scaling_initializer(scale = 2)` será usado para esta inicialización. Para el lector interesado, la inicialización con `tf.contrib.layers.xavier_initializer()` también se puede usar y se deja como comentario:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HusXM0t53gG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.variance_scaling_initializer(scale = 2) # tf.contrib.layers.xavier_initializer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39PfsbP93gHA",
        "colab_type": "text"
      },
      "source": [
        "#### Definimos la clase QNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDkeYeGJ3gHA",
        "colab_type": "text"
      },
      "source": [
        "Definiremos la clase `QNetwork()` como se resume enseguida. Tendrá un constructor `__init__` y las funciones `_build_model()`, `predict()` y `update()`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjVKCOAL3gHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QNetwork():\n",
        "    def __init__(self, scope=\"QNet\", VALID_ACTIONS=[0, 1, 2, 3]):\n",
        "        self.scope = scope\n",
        "        self.VALID_ACTIONS = VALID_ACTIONS\n",
        "        with tf.variable_scope(scope):\n",
        "            self._build_model()\n",
        "            \n",
        "    def _build_model(self):\n",
        "        # input placeholders; input is 4 frames of shape 84x84 \n",
        "        self.tf_X = tf.placeholder(shape=[None, 84, 84, 4], dtype=tf.uint8, name=\"X\")\n",
        "        # TD\n",
        "        self.tf_y = tf.placeholder(shape=[None], dtype=tf.float32, name=\"y\")\n",
        "        # action\n",
        "        self.tf_actions = tf.placeholder(shape=[None], dtype=tf.int32, name=\"actions\")\n",
        "\n",
        "        # normalize input\n",
        "        X = tf.to_float(self.tf_X) / 255.0\n",
        "        batch_size = tf.shape(self.tf_X)[0]\n",
        "\n",
        "#-------------\n",
        "        \n",
        "        if (NET == 'bigger'):\n",
        " \n",
        "           # bigger net\n",
        "\n",
        "           # 3 conv layers\n",
        "           conv1 = tf.contrib.layers.conv2d(X, 32, 8, 4, padding='VALID', activation_fn=tf.nn.relu, weights_initializer=winit)\n",
        "           conv2 = tf.contrib.layers.conv2d(conv1, 64, 4, 2, padding='VALID', activation_fn=tf.nn.relu, weights_initializer=winit)\n",
        "           conv3 = tf.contrib.layers.conv2d(conv2, 64, 3, 1, padding='VALID', activation_fn=tf.nn.relu, weights_initializer=winit)\n",
        "\n",
        "           # fully connected layers\n",
        "           flattened = tf.contrib.layers.flatten(conv3)\n",
        "           fc1 = tf.contrib.layers.fully_connected(flattened, 512, activation_fn=tf.nn.relu, weights_initializer=winit)\n",
        "\n",
        "\n",
        "        elif (NET == 'smaller'): \n",
        " \n",
        "           # smaller net\n",
        "   \n",
        "           # 2 conv layers\n",
        "           conv1 = tf.contrib.layers.conv2d(X, 16, 8, 4, padding='VALID', activation_fn=tf.nn.relu, weights_initializer=winit)\n",
        "           conv2 = tf.contrib.layers.conv2d(conv1, 32, 4, 2, padding='VALID', activation_fn=tf.nn.relu, weights_initializer=winit)\n",
        "\n",
        "           # fully connected layers\n",
        "           flattened = tf.contrib.layers.flatten(conv2)\n",
        "           fc1 = tf.contrib.layers.fully_connected(flattened, 256, activation_fn=tf.nn.relu, weights_initializer=winit)  \n",
        "#-------------         \n",
        "\n",
        "       \n",
        "\n",
        "        # Q(s,a)\n",
        "        self.predictions = tf.contrib.layers.fully_connected(fc1, len(self.VALID_ACTIONS), activation_fn=None, weights_initializer=winit)\n",
        "\n",
        "\n",
        "        action_one_hot = tf.one_hot(self.tf_actions, tf.shape(self.predictions)[1], 1.0, 0.0, name='action_one_hot')\n",
        "        self.action_predictions = tf.reduce_sum(self.predictions * action_one_hot, reduction_indices=1, name='act_pred')\n",
        " \n",
        "        if (LOSS == 'L2'):\n",
        "           # L2 loss\n",
        "           self.loss = tf.reduce_mean(tf.squared_difference(self.tf_y, self.action_predictions), name='loss')\n",
        "        elif (LOSS == 'huber'):\n",
        "           # Huber loss\n",
        "           self.loss = tf.reduce_mean(huber_loss(self.tf_y-self.action_predictions), name='loss')\n",
        "        \n",
        "\n",
        "        # optimizer \n",
        "        #self.optimizer = tf.train.RMSPropOptimizer(learning_rate=0.00025, momentum=0.95, epsilon=0.01)\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=2e-5)\n",
        "        self.train_op = self.optimizer.minimize(self.loss, global_step=tf.contrib.framework.get_global_step())\n",
        "        \n",
        "    def predict(self, sess, s):\n",
        "        return sess.run(self.predictions, { self.tf_X: s})\n",
        "\n",
        "    def update(self, sess, s, a, y):\n",
        "        feed_dict = { self.tf_X: s, self.tf_y: y, self.tf_actions: a }\n",
        "        _, loss = sess.run([self.train_op, self.loss], feed_dict)\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3gbaaU43gHE",
        "colab_type": "text"
      },
      "source": [
        "Analicemos en detalle durante las siguientes subsecciones que hay dentro de la clase `QNetwork()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1R-Y-j13gHF",
        "colab_type": "text"
      },
      "source": [
        "##### El constructor `__init__` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkBKUNJd3gHF",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "class QNetwork():\n",
        "    def __init__(self, scope = 'QNet', VALID_ACTIONS = [0,1,2,3]):\n",
        "        self.scope = scope\n",
        "        self.VALID_ACTIONS = VALID_ACTIONS\n",
        "        with tf.variable_scope(scope):\n",
        "            self._build_model()      \n",
        "```  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXRVpzg23gHG",
        "colab_type": "text"
      },
      "source": [
        "##### La función `_build_model()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-juoNUy73gHH",
        "colab_type": "text"
      },
      "source": [
        "En la función `_build_model()`, primero definiremos los placeholders `tf_X`, `tf_Y` y `tf_actions`. Nótese que los frames de las imágenes son almacenados en un formato `uint8` en el replay del buffer para guardar memoria, y se normalizarán al convertirlos a `float` y luego dividiéndolos por $255.0$ para colocar el input `X` en el rango $(0,1)$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXb5roow3gHH",
        "colab_type": "text"
      },
      "source": [
        "```python    \n",
        "    def _build_model(self):\n",
        "        # input placeholders; input is 4 frames of shape 84x84\n",
        "        self.tf_X = tf.placeholder(shape = [None,84,84,4], dtype = tf.float32, name = 'X')\n",
        "        # TD\n",
        "        self.tf_Y = tf.placeholder(shape = [None], dtype = tf.float32, name = 'y')\n",
        "        # actions \n",
        "        self.tf_actions = tf.placeholder(shape = [None], dtype = tf.int32, name = 'actions')\n",
        "        # normalize input \n",
        "        X = tf.to_float(self.tf_X)/255\n",
        "        batch_size = tf.shape(self.tf_X)[0]\n",
        "        \n",
        "```         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ruh2Gbc3gHI",
        "colab_type": "text"
      },
      "source": [
        "Ahora definamos las **capas de convolución**: Como se mencionó, tenemos una opción para nuestra red `bigger` y otra `smaller`.\n",
        "\n",
        "La red `bigger` tiene $3$ capas convolucionales, seguida de $1$ capa completamente conectada.\n",
        "\n",
        "La red `smaller` tiene $2$ capas convolucionales, seguida de $1$ capa completamente conectada. \n",
        "\n",
        "Podemos definir las capas convolucionales en TensorFLow usando `tf.contrib.layers.conv2d()`, y capas completamente conectadas usando `tf.contrib.layers.fully_connected()`. Notemos que, luego de la última capa convolucional, tenemos que aplanar nuestro output antes de pasarlo a la capa completamente conectada, para lo cuál se usa `tf.contrib.layers.flatten()`. Usaremos el objeto `winit` como nuestro inicializador de pesos, que definimos anteriormente:   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQW67knb3gHI",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "        if (NET == 'bigger'):\n",
        "            # bigger net\n",
        "            # 3 conv layers\n",
        "            conv1 = tf.contrib.layers.conv2d(X, 32, 8, 4, padding = 'VALID', activation_fn = tf.nn.relu, weights_initializer = winit)\n",
        "            conv2 = tf.contrib.layers.conv2d(conv1, 64, 4, 2, padding = 'VALID', activation_fn = tf.nn.relu, weights_initializer = winit)\n",
        "            conv3 = tf.contrib.layers.conv2d(conv2, 64, 3, 1, padding = 'VALID', activation_fn = tf.nn.relu, weights_initializer = winit)\n",
        "            #fully connected layers\n",
        "            flattened = tf.contrib.layers.flatten(conv3)\n",
        "            fc1 = tf.contrib.layers.fully_connected(flattened, 512, activation_fn = tf.nn.relu, weights_initializer = winit)\n",
        "        \n",
        "        elif (NET == 'smaller'):\n",
        "            # smaller net\n",
        "            # 2 conv layers\n",
        "            conv1 = tf.contrib.layers.conv2d(X, 16, 8, 4, padding = 'VALID', activation_fn = tf.nn.relu, weights_initializer = winit)\n",
        "            conv2 = tf.contrib.layers.conv2d(conv1, 32, 4, 2, padding = 'VALID', activation_fn = tf.nn.relu, weights_initializer = winit)\n",
        "            # fully connected layers\n",
        "            flattened = tf.contrib.layers.flatten(conv2)\n",
        "            fc1 = tf.contrib.layers.fully_connected(flattened, 256, activation_fn = tf.nn.relu, weights_initializer = winit)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFSGMeoJ3gHJ",
        "colab_type": "text"
      },
      "source": [
        "Continuamos por definir la **capa completamente conectada**: Para terminar en la función `_build_model()`, tenemos una capa completamente conectada cuyo tamaño coincide con el número de posible de acciones, que se especifica mediante `len(self.VALID_ACTIONS)`. El output de esta capa se almacena en `self.predictions`, y representa $Q(s,a)$, y que vimos en la teoría de este cuaderno. \n",
        "\n",
        "Las acciones que pasamos a esta función, i.e., `self.tf_actions` debe ser convertida al formato one-hot, para lo cuál usamos `tf.one_hot()`. Nótese que el formato `one_hot` es una manera de representar el número de acción como un array binario con cero en todas las acciones, expecto por una acción, la cuál se almacena con un valor de `1.0`. \n",
        "\n",
        "Luego se multiplican las predicciones con las acciones en formato one-hot usando `self.predictions * action_one_hot`, y el resultado se suma usando `tf.reduce_sum()`; esa cantidad finalmente se almacena en la variable `self.action_predictions`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_siGoRU3gHJ",
        "colab_type": "text"
      },
      "source": [
        "```python        \n",
        "        # Q(s,a)\n",
        "        self.predictions = tf.contrib.layers.fully_connected(fc1, len(self.VALID_ACTIONS), activation_fn = None, weights_initializer = winit)\n",
        "        action_one_hot = tf.one_hot(self.tf_actions, tf.shape(self.predictions)[1], 1.0, 0.0, name = 'action_one_hot')\n",
        "        self.action_predictions = tf.reduce_sum(self.predictions * action_one_hot, reduction_indices = 1, name = 'act_pred')\n",
        "```        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GQHnXFP3gHK",
        "colab_type": "text"
      },
      "source": [
        "Calculamos la **función de pérdida** para el entrenamiento de la red: Calculamos la función de pérdida para el entrenamiento de la red, que estará almacenada en `self.loss`, usando la pérdida L2 o la de Huber, que se determina usando la variable `LOSS`. \n",
        "\n",
        "Para la pérdida L2, usamos la función `tf.squared_difference()`, y para la de Huber usamos `huber_loss()` que pronto definiremos. La pérdida se promedia sobre muchas muestras, y para esto usaremos la función `tf.reduce_mean()`. \n",
        "\n",
        "Nótese que se calculará la pérdida entre el placeholder `tf_y` definido al comienzo y la variable `action_predictions` que obtuvimos en el último paso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTvkv1zu3gHK",
        "colab_type": "text"
      },
      "source": [
        "```python        \n",
        "        if (LOSS == 'L2'):\n",
        "            # L2 loss\n",
        "            self.loss = tf.reduce_mean(tf.squared_difference(self.tf_y, self.action_predictions), name = 'loss')\n",
        "        elif (LOSS == 'huber'):\n",
        "            # Huber loss\n",
        "            self.loss = tf.reduce_mean(huber_loss(self.tf_y-self.action_predictions), name = 'loss')\n",
        "```            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCpUrZua3gHL",
        "colab_type": "text"
      },
      "source": [
        "Usando un **optimizador**: Usaremos el optimizador RMSprop o Adam, y lo almacenaremos en `self.optimizer`. Nuestro objetivo de aprendizaje estará en minimizar `self.loss`, y para esto usaremos `self.optimizer.minimize()`. Esta última cantidad está almacenada en `self.train_op`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMey_GFA3gHL",
        "colab_type": "text"
      },
      "source": [
        "```python        \n",
        "        # optimizer\n",
        "        # self.optimizer = tf.train.RMSPropOptimizer(learning_rate = 0.00025, momentum = 0.95, epsilon = 0.01)\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate = 2e-5)\n",
        "        self.train_op = self.optimizer.minimizer(self.loss, global_step = tf.contrib.framework.get_global_step())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H-g16zS3gHL",
        "colab_type": "text"
      },
      "source": [
        "##### La función `predict()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH-Gdcr83gHM",
        "colab_type": "text"
      },
      "source": [
        "En la función `predict()`, corremos la función `self.predictions` definida previamente usando `sess.run()` de TensorFlow, donde `sess` es el objeto de tipo `tf.Session()` que se para como parámetro a esta función.\n",
        "\n",
        "Los estados se pasan como argumentos en esta función en la variable `s`, el cuál se pasará al placeholder, `tf_X`: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyfeZcne3gHM",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "    def predict(self, sess, s):\n",
        "        return sess.run(self.predictions, {self.tf_X: s})\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYeCKj-T3gHN",
        "colab_type": "text"
      },
      "source": [
        "##### La función `update()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA4BQA-B3gHN",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, en la función `update()`, llamaremos los objetos `train_op` y `loss`, y alimentamos el diccionario `a` en los placeholders involucrados en estas operaciones, el cuál llamamos `feed_dict`. Los estados estan almacenados en `s`, las acciones en `a`, y los targets en `y`: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuJR-f3M3gHO",
        "colab_type": "text"
      },
      "source": [
        "```python    \n",
        "    def update(self, sess, s, a, y):\n",
        "        feed_dict = {self.tf_X : s, self.tf_y : y, self.tf_actions : a}\n",
        "        _, loss = sess.run([self.train_op,self.loss], feed_dict)\n",
        "        return loss\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ4DfWLM3gHP",
        "colab_type": "text"
      },
      "source": [
        "#### Definimos la función `huber_loss()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Soa82NnO3gHQ",
        "colab_type": "text"
      },
      "source": [
        "La función de pérdida de Huber es una mezcla entre las pérdidas L1 Y L2. Cuando el input es menor que $1$, toma el valor de la pérdida L2, y toma la L1 en otro caso:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfwETdG83gHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# huber loss\n",
        "def huber_loss(x):\n",
        "    condition = tf.abs(x) < 1.0\n",
        "    output1 = 0.5 * tf.square(x)\n",
        "    output2 = tf.abs(x) - 0.5\n",
        "    return tf.where(condition, output1, output2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "illmIEdhdRsc",
        "colab_type": "text"
      },
      "source": [
        "### Usando el archivo funcs.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwt96xJ3dRsc",
        "colab_type": "text"
      },
      "source": [
        "#### Importamos los paquetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDCClK08dRsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzikqWmmdRsg",
        "colab_type": "text"
      },
      "source": [
        "#### Definimos la clase `ImageProcess()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLOn9dFBdRsh",
        "colab_type": "text"
      },
      "source": [
        "Ahora convertimos las imágenes de tamaño 210x160x3 y de tipo RGB del emulador de Atari a una imagen de escala de grises 84x84. Para esto, crearemos la clase `ImageProcess()` y usamos funciones de utilidad de TensorFlow, tales como:\n",
        "- `rgb_to_gray_scale()` para convertir la imagen de RGB a escala de grises \n",
        "- `crop_to_bounding_box()` para recortar la región de interes de una imagen\n",
        "- `resize_images()` para redimensionar la imagen a 84x84\n",
        "- `squeeze()` para remover una dimensión del input\n",
        "Finalmente incluímos una función `process()` a la clase y que se encargará de las operaciones que invocarán la función `sess.run()` en `self.output()`.\n",
        "\n",
        "Nótese que pasamos la variable `state` como un diccionario:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQVV_3padRsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert raw Atari RGB image of size 210x160x3 into 84x84 grayscale image\n",
        "class ImageProcess():\n",
        "    def __init__(self):\n",
        "        with tf.variable_scope(\"state_processor\"):\n",
        "            self.input_state = tf.placeholder(shape = [210, 160, 3], dtype = tf.uint8)\n",
        "            self.output = tf.image.rgb_to_grayscale(self.input_state)\n",
        "            self.output = tf.image.crop_to_bounding_box(self.output, 34, 0, 160, 160)\n",
        "            self.output = tf.image.resize_images(self.output, [84, 84], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "            self.output = tf.squeeze(self.output)\n",
        "    def process(self, sess, state):\n",
        "        return sess.run(self.output, { self.input_state: state })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMTmcndVdRsk",
        "colab_type": "text"
      },
      "source": [
        "#### Copiamos los parámetros de una red a otra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n7gfn8VdRsl",
        "colab_type": "text"
      },
      "source": [
        "El siguiente paso consiste en escribir una función llamada `copy_model_parameters()`, la cuál tomará como argumentos:\n",
        "\n",
        "- `sess`: objeto de tipo `tf.Session()`\n",
        "- qnet1 : Red neuronal (en nuestro caso será Q-network)\n",
        "- qnet2 : Red neuronal (en nuestro caso será la red target) \n",
        "\n",
        "La función copiará los valores de parámetros de `qnet1` a `qnet2`: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7-m5JhhdRsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy params from qnet1 to qnet2\n",
        "def copy_model_parameters(sess, qnet1, qnet2):\n",
        "    q1_params = [t for t in tf.trainable_variables() if t.name.startswith(qnet1.scope)]\n",
        "    q1_params = sorted(q1_params, key=lambda v: v.name)\n",
        "    q2_params = [t for t in tf.trainable_variables() if t.name.startswith(qnet2.scope)]\n",
        "    q2_params = sorted(q2_params, key=lambda v: v.name)\n",
        "    update_ops = []\n",
        "    for q1_v, q2_v in zip(q1_params, q2_params):\n",
        "        op = q2_v.assign(q1_v)\n",
        "        update_ops.append(op)\n",
        "    sess.run(update_ops)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N62Pe_t6dRsp",
        "colab_type": "text"
      },
      "source": [
        "#### Definimos una función para usar la estrategia $\\epsilon$-greedy para explorar o aprovechar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9CkolIHdRsq",
        "colab_type": "text"
      },
      "source": [
        "Ahora escribiremos una función llamada `epsilon_greedy_policy()`, la cuál explorará o aprovechará dependiendo de si un número real aleatorio calculado usando la función de numpy `np.random.rand()` es menor que `epsilon`, parámetro descrito anteriormente en la estrategia $\\epsilon$-greedy.\n",
        "\n",
        "Para la exploración, todas las acciones son equiprobables con probabilidad igual a $\\frac{1}{\\text{num_actions}}$, donde `num_actions` es el número posible de acciones (que para nuestro caso en el juego Breakout es $4$).\n",
        "\n",
        "Y para aprovechar, usaremos la función `predict()` de la $Q$-Network para obtener los $Q$-valores e identificar que acciones tiene el valor de $Q$ más alto, todo esto mediante la función de numpy `np.argmax()`. La salida de esta función es la probabilidad de cada una de las acciones, que para el aprovechar, tendrá todos sus valores `0` excepto por la acción que tiene el valor de $Q$ más alto, para la cuál se le asignará un valor de `1.0`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOWvNSiUdRsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epsilon-greedy\n",
        "def epsilon_greedy_policy(qnet, num_actions):\n",
        "    def policy_fn(sess, observation, epsilon):\n",
        "        if (np.random.rand() < epsilon):  \n",
        "          # explore: equal probabiities for all actions\n",
        "          A = np.ones(num_actions, dtype=float) / float(num_actions)\n",
        "        else:\n",
        "          # exploit \n",
        "          q_values = qnet.predict(sess, np.expand_dims(observation, 0))[0]\n",
        "          max_Q_action = np.argmax(q_values)\n",
        "          A = np.zeros(num_actions, dtype=float)\n",
        "          A[max_Q_action] = 1.0 \n",
        "        return A\n",
        "    return policy_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q96PZOFdRsu",
        "colab_type": "text"
      },
      "source": [
        "#### La función `populate_replay_mem` para poblar la memoria de replay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4efyKUeSdRsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# populate replay memory\n",
        "def populate_replay_mem(sess, env, state_processor, replay_memory_init_size, policy, epsilon_start, epsilon_end, epsilon_decay_steps, VALID_ACTIONS, Transition):\n",
        "    state = env.reset()\n",
        "    state = state_processor.process(sess, state)\n",
        "    state = np.stack([state] * 4, axis=2)\n",
        "\n",
        "    delta_epsilon = (epsilon_start - epsilon_end)/float(epsilon_decay_steps)\n",
        "\n",
        "    replay_memory = []\n",
        "\n",
        "    for i in range(replay_memory_init_size):\n",
        "        epsilon = max(epsilon_start - float(i) * delta_epsilon, epsilon_end)\n",
        "        action_probs = policy(sess, state, epsilon)\n",
        "        action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "\n",
        "        env.render()   \n",
        "        next_state, reward, done, _ = env.step(VALID_ACTIONS[action])\n",
        "\n",
        "        next_state = state_processor.process(sess, next_state)\n",
        "        next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)\n",
        "        replay_memory.append(Transition(state, action, reward, next_state, done))\n",
        "\n",
        "        if done:\n",
        "            state = env.reset()\n",
        "            state = state_processor.process(sess, state)\n",
        "            state = np.stack([state] * 4, axis=2)\n",
        "        else:\n",
        "            state = next_state\n",
        "    return replay_memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKiNKW0TdRsz",
        "colab_type": "text"
      },
      "source": [
        "Veamos acontinuación cada parte de la función"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBccxDwmdRsz",
        "colab_type": "text"
      },
      "source": [
        "Escribiremos una función `populate_replay_mem` para poblar el replay buffer con un número de muestras `replay_memory_init_size`.\n",
        "\n",
        "Primero, reseteamos nuestro ambiente usando `env.reset()`. Luego procesamos el estado obtenido del reset. Necesitamos 4 frames para cada estado, ya que el agente por otra parte no tiene manera de determinar el movimiento de la paleta o su velocidad. \n",
        "\n",
        "Para el primer frame, apilamos cuatro copias. También calculamos `delta_epsilon`, que es la cantidad que decrece epsilon por time step. \n",
        "\n",
        "La memoria de replay se inicializa como una lista vacía:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fj0_D2wdRs0",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "# populate replay memory\n",
        "def populate_replay_mem(sess, env, state_processor, replay_memory_init_size, policy, epsilon_start, epsilon_end, epsilon_decay_steps, VALID_ACTIONS, Transition):\n",
        "    state = env.reset()\n",
        "    state = state_processor.process(sess, state)\n",
        "    state = np.stack([state] * 4, axis=2)\n",
        "\n",
        "    delta_epsilon = (epsilon_start - epsilon_end)/float(epsilon_decay_steps)\n",
        "\n",
        "    replay_memory = []\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OyhAHwFdRs0",
        "colab_type": "text"
      },
      "source": [
        "Ahora calculamos las **probabilidades de acciones**: Lo que significa es que haremos, un loop por `replay_memory_init_size` cuatro veces, disminuiremos epsilon por `delta_epsilon`, y calcularemos las probabilidades de acciones, almacenadas en la variable `action_probs`, usando `policy()`, que fue pasada como argumento. \n",
        "\n",
        "La acción exacta de la variable `action_probs` se determina al muestrear usando `np.random.choice`. Luego, `env.render()` renderiza el ambiente, y luego pasamos la acción a `env.step()`, que dará como output:\n",
        "- el siguiente estado (almacenado en `next_state`)\n",
        "- la recompensa por la transición\n",
        "- si el episodio terminó o no (almacenado en `done`)\n",
        "\n",
        "Lo que vendrá ahora será **Append to replay buffer**: Ahora procesamos el siguiente estado y lo appendamos a la memoria de replay, la tupla `(state, actions, reward, next_state, done)`. Si el episodio terminó, entonces reseteamos el ambiente a una nueva ronda del juego, procesamos la imagen y apilamos cuatro veces, como hicimos hace un momento. Si el episodio no termina aún, el nuevo estado se convierte en el estado actual para el siguiente time step, y procedemos de esta manera hasta que el ciclo termine:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JfOqCcDdRs1",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "for i in range(replay_memory_init_size):\n",
        "        epsilon = max(epsilon_start - float(i) * delta_epsilon, epsilon_end)\n",
        "        action_probs = policy(sess, state, epsilon)\n",
        "        action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "\n",
        "        env.render()   \n",
        "        next_state, reward, done, _ = env.step(VALID_ACTIONS[action])\n",
        "\n",
        "        next_state = state_processor.process(sess, next_state)\n",
        "        next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)\n",
        "        replay_memory.append(Transition(state, action, reward, next_state, done))\n",
        "\n",
        "        if done:\n",
        "            state = env.reset()\n",
        "            state = state_processor.process(sess, state)\n",
        "            state = np.stack([state] * 4, axis=2)\n",
        "        else:\n",
        "            state = next_state\n",
        "    return replay_memory\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpOFkTOkRZw6",
        "colab_type": "text"
      },
      "source": [
        "### Usando el archivo dqn.py "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoisniaQRZw7",
        "colab_type": "text"
      },
      "source": [
        "#### Importamos los paquetes necesarios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6BX97JPRZw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import itertools\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from collections import deque, namedtuple\n",
        "\n",
        "from model import *\n",
        "from funcs import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3cGyt7ORZxA",
        "colab_type": "text"
      },
      "source": [
        "#### Set el juego y escogemos acciones válidas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_e5r-AYRZxB",
        "colab_type": "text"
      },
      "source": [
        "Ahora haremos el set de nuestro juego. Escojamos el juego `BreakoutDeterministic-v4`, que es una versión reciente de Breakout v0. Este juego tiene 4 acciones, enumeradas de 0 a 3 y representan:\n",
        "\n",
        "- `0`: quedarse quieto\n",
        "- `1`: disparar\n",
        "- `2`: mover hacia la izquierda\n",
        "- `3`: mover hacia la derecha\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emsFyCiARZxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAME = \"BreakoutDeterministic-v4\" # \"BreakoutDeterministic-v0\"\n",
        "\n",
        "# Atari Breakout actions: 0 (noop), 1 (fire), 2 (left) and 3 (right) \n",
        "VALID_ACTIONS = [0, 1, 2, 3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKTGgtDuRZxG",
        "colab_type": "text"
      },
      "source": [
        "#### Set la moda(entrenamiento/validación) y empecemos las iteraciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWzFc_85RZxH",
        "colab_type": "text"
      },
      "source": [
        "Haremos el set de la moda en la variable `train_or_test`. Comencemos con `'train'` (más adelante se podrá hacer el set de esta variable a `'test'` para evaluar el modelo luego de que se complete el entrenamiento). También haremos el entrenamiento desde el principio desde la iteración `0`: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEiVGhc4RZxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set parameters for running\n",
        "\n",
        "train_or_test = 'train' #'test' #'train'\n",
        "train_from_scratch = True\n",
        "start_iter = 0\n",
        "start_episode = 0\n",
        "epsilon_start = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnuVL9TyRZxN",
        "colab_type": "text"
      },
      "source": [
        "#### Creamos el ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDO-MJmGRZxN",
        "colab_type": "text"
      },
      "source": [
        "Crearemos el objeto de ambiente `env`, el cuál creará el juego `GAME`. \n",
        "\n",
        "- `env.action_space.n` va a hacer el print del número de acciones en este ambiente.\n",
        "- `env.reset()` va a hacer el reset del juego y nos retornará el estado/observación inicial.\n",
        "- `observation.shape` va a hacer el print del shape del espacio de estados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9z_knBbRZxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.envs.make(GAME)\n",
        "\n",
        "print(\"Action space size: {}\".format(env.action_space.n))\n",
        "observation = env.reset()\n",
        "print(\"Observation space shape: {}\".format(observation.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMYP1-GWRZxQ",
        "colab_type": "text"
      },
      "source": [
        "#### Creamos los paths y directorios para almacenar los archivos de checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leFjNGn0RZxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# experiment dir\n",
        "experiment_dir = os.path.abspath(\"./experiments/{}\".format(env.spec.id))\n",
        "\n",
        "\n",
        "# create ckpt directory    \n",
        "checkpoint_dir = os.path.join(experiment_dir, \"ckpt\")\n",
        "checkpoint_path = os.path.join(checkpoint_dir, \"model\")\n",
        "    \n",
        "if not os.path.exists(checkpoint_dir):\n",
        "   os.makedirs(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOAn6QAhRZxX",
        "colab_type": "text"
      },
      "source": [
        "#### La función `deep_q_learning()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3-BgW_ORZxY",
        "colab_type": "text"
      },
      "source": [
        "Crearemos a continuación la función `deep_q_learning()`, la cual tendrá una gran lista de argumentos que involucran el objeto de la sesión de TensorFLow, el ambiente, los objetos de las redes Q-network y target, y así. \n",
        "\n",
        "La política que se usará será la construida `epsilon_greedy_policy()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "-ydnYqfKRZxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deep_q_learning(sess, env, q_net, target_net, state_processor, num_episodes, train_or_test='train', train_from_scratch=True,\n",
        "                    start_iter=0, start_episode=0, replay_memory_size=250000, replay_memory_init_size=50000, update_target_net_every=10000,\n",
        "                    gamma=0.99, epsilon_start=1.0, epsilon_end=[0.1,0.01], epsilon_decay_steps=[1e6,1e6], batch_size=32):\n",
        "                   \n",
        "    Transition = namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "\n",
        "    # policy \n",
        "    policy = epsilon_greedy_policy(q_net, len(VALID_ACTIONS))\n",
        "\n",
        "\n",
        "    # populate replay memory\n",
        "    if (train_or_test == 'train'):\n",
        "      print(\"populating replay memory\")\n",
        "      replay_memory = populate_replay_mem(sess, env, state_processor, replay_memory_init_size, policy, epsilon_start, \n",
        "                                                       epsilon_end[0], epsilon_decay_steps[0], VALID_ACTIONS, Transition)\n",
        "\n",
        "\n",
        "    # epsilon start\n",
        "    if (train_or_test == 'train'):\n",
        "       delta_epsilon1 = (epsilon_start - epsilon_end[0])/float(epsilon_decay_steps[0])     \n",
        "       delta_epsilon2 = (epsilon_end[0] - epsilon_end[1])/float(epsilon_decay_steps[1])    \n",
        "       if (train_from_scratch == True):\n",
        "          epsilon = epsilon_start\n",
        "       else:\n",
        "          if (start_iter <= epsilon_decay_steps[0]):\n",
        "             epsilon = max(epsilon_start - float(start_iter) * delta_epsilon1, epsilon_end[0])\n",
        "          elif (start_iter > epsilon_decay_steps[0] and start_iter < epsilon_decay_steps[0]+epsilon_decay_steps[1]):\n",
        "             epsilon = max(epsilon_end[0] - float(start_iter) * delta_epsilon2, epsilon_end[1])\n",
        "          else:\n",
        "             epsilon = epsilon_end[1]      \n",
        "    elif (train_or_test == 'test'):\n",
        "       epsilon = epsilon_end[1]\n",
        "\n",
        "\n",
        "    # total number of time steps \n",
        "    total_t = start_iter\n",
        "\n",
        "\n",
        "    for ep in range(start_episode, num_episodes):\n",
        "\n",
        "        # save ckpt\n",
        "        saver.save(tf.get_default_session(), checkpoint_path)\n",
        "\n",
        "        # env reset\n",
        "        state = env.reset()\n",
        "        state = state_processor.process(sess, state)\n",
        "        state = np.stack([state] * 4, axis=2)\n",
        "\n",
        "        loss = 0.0\n",
        "        time_steps = 0\n",
        "        episode_rewards = 0.0\n",
        "    \n",
        "        ale_lives = 5\n",
        "        info_ale_lives = ale_lives\n",
        "        steps_in_this_life = 1000000\n",
        "        num_no_ops_this_life = 0\n",
        "\n",
        "\n",
        "\n",
        "        while True:\n",
        "            \n",
        "            if (train_or_test == 'train'):\n",
        "              #epsilon = max(epsilon - delta_epsilon, epsilon_end) \n",
        "              if (total_t <= epsilon_decay_steps[0]):\n",
        "                    epsilon = max(epsilon - delta_epsilon1, epsilon_end[0]) \n",
        "              elif (total_t >= epsilon_decay_steps[0] and total_t <= epsilon_decay_steps[0]+epsilon_decay_steps[1]):\n",
        "                    epsilon = epsilon_end[0] - (epsilon_end[0]-epsilon_end[1]) / float(epsilon_decay_steps[1]) * float(total_t-epsilon_decay_steps[0]) \n",
        "                    epsilon = max(epsilon, epsilon_end[1])           \n",
        "              else:\n",
        "                    epsilon = epsilon_end[1]\n",
        "\n",
        "\n",
        "              # update target net\n",
        "              if total_t % update_target_net_every == 0:\n",
        "                 copy_model_parameters(sess, q_net, target_net)\n",
        "                 print(\"\\n copied params from Q net to target net \")\n",
        "\n",
        "                   \n",
        "            time_to_fire = False\n",
        "            if (time_steps == 0 or ale_lives != info_ale_lives):\n",
        "               # new game or new life \n",
        "               steps_in_this_life = 0\n",
        "               num_no_ops_this_life = np.random.randint(low=0,high=7)\n",
        "               action_probs = [0.0, 1.0, 0.0, 0.0]  # fire\n",
        "               time_to_fire = True\n",
        "               if (ale_lives != info_ale_lives):\n",
        "                  ale_lives = info_ale_lives\n",
        "            else:\n",
        "               action_probs = policy(sess, state, epsilon)\n",
        "\n",
        "            steps_in_this_life += 1 \n",
        "            if (steps_in_this_life < num_no_ops_this_life and not time_to_fire):\n",
        "               # no-op\n",
        "               action_probs = [1.0, 0.0, 0.0, 0.0] # no-op\n",
        "\n",
        "\n",
        "\n",
        "            action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "             \n",
        "            env.render()\n",
        "            next_state_img, reward, done, info = env.step(VALID_ACTIONS[action]) \n",
        "            \n",
        "            info_ale_lives = int(info['ale.lives'])\n",
        "\n",
        "            # rewards = -1,0,+1 as done in the paper\n",
        "            #reward = np.sign(reward)\n",
        "\n",
        "            next_state_img = state_processor.process(sess, next_state_img)\n",
        "\n",
        "            # state is of size [84,84,4]; next_state_img is of size[84,84]\n",
        "            #next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)\n",
        "            next_state = np.zeros((84,84,4),dtype=np.uint8)\n",
        "            next_state[:,:,0] = state[:,:,1] \n",
        "            next_state[:,:,1] = state[:,:,2]\n",
        "            next_state[:,:,2] = state[:,:,3]\n",
        "            next_state[:,:,3] = next_state_img    \n",
        "\n",
        "\n",
        "            episode_rewards += reward  \n",
        "            time_steps += 1\n",
        "\n",
        " \n",
        "            if (train_or_test == 'train'):\n",
        "\n",
        "                # if replay memory is full, pop the first element\n",
        "                if len(replay_memory) == replay_memory_size:\n",
        "                    replay_memory.pop(0)\n",
        "\n",
        "                # save transition to replay memory\n",
        "                # done = True in replay memory for every loss of life \n",
        "                if (ale_lives == info_ale_lives):\n",
        "                   replay_memory.append(Transition(state, action, reward, next_state, done))   \n",
        "                else:\n",
        "                   #print('loss of life ')\n",
        "                   replay_memory.append(Transition(state, action, reward, next_state, True))               \n",
        "\n",
        "                # sample a minibatch from replay memory\n",
        "                samples = random.sample(replay_memory, batch_size)\n",
        "                states_batch, action_batch, reward_batch, next_states_batch, done_batch = map(np.array, zip(*samples))\n",
        "\n",
        "\n",
        "                # calculate q values and targets \n",
        "                q_values_next = target_net.predict(sess, next_states_batch)\n",
        "                greedy_q = np.amax(q_values_next, axis=1) \n",
        "                targets_batch = reward_batch + np.invert(done_batch).astype(np.float32) * gamma * greedy_q\n",
        "               \n",
        "\n",
        "                # update net \n",
        "                if (total_t % 4 == 0):\n",
        "                   states_batch = np.array(states_batch)\n",
        "                   loss = q_net.update(sess, states_batch, action_batch, targets_batch)\n",
        "\n",
        "            if done:\n",
        "                #print(\"done: \", done)\n",
        "                break\n",
        "\n",
        "            state = next_state\n",
        "            total_t += 1\n",
        "            \n",
        "\n",
        "        if (train_or_test == 'train'): \n",
        "           print('\\n Eisode: ', ep, '| time steps: ', time_steps, '| total episode reward: ', episode_rewards, '| total_t: ', total_t, '| epsilon: ', epsilon, '| replay mem size: ', len(replay_memory))\n",
        "        elif (train_or_test == 'test'):\n",
        "           print('\\n Eisode: ', ep, '| time steps: ', time_steps, '| total episode reward: ', episode_rewards, '| total_t: ', total_t, '| epsilon: ', epsilon)\n",
        "\n",
        "\n",
        "        if (train_or_test == 'train'):\n",
        "            f = open(\"experiments/\" + str(env.spec.id) + \"/performance.txt\", \"a+\")\n",
        "            f.write(str(ep) + \" \" + str(time_steps) + \" \" + str(episode_rewards) + \" \" + str(total_t) + \" \" + str(epsilon) + '\\n')  \n",
        "            f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNA2847-RZxb",
        "colab_type": "text"
      },
      "source": [
        "Veamos a detalle cada parte de esta función."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWlMpKl8RZxc",
        "colab_type": "text"
      },
      "source": [
        "##### Definimos la función `deep_q_learning()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3ruGd0WRZxc",
        "colab_type": "text"
      },
      "source": [
        "Aquí empezamos con la definición de la función la cuál usará la política `epsilon_greedy_policy()`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY4JHwTMRZxd",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "def deep_q_learning(sess, env, q_net, target_net, state_processor, num_episodes, train_or_test='train', train_from_scratch=True,\n",
        "                    start_iter=0, start_episode=0, replay_memory_size=250000, replay_memory_init_size=50000, update_target_net_every=10000,\n",
        "                    gamma=0.99, epsilon_start=1.0, epsilon_end=[0.1,0.01], epsilon_decay_steps=[1e6,1e6], batch_size=32):\n",
        "                   \n",
        "    Transition = namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "\n",
        "    # policy \n",
        "    policy = epsilon_greedy_policy(q_net, len(VALID_ACTIONS))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MZkYjOWRZxd",
        "colab_type": "text"
      },
      "source": [
        "##### Poblamos la memoria de replay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkXLZ9A-RZxe",
        "colab_type": "text"
      },
      "source": [
        "Poblaremos la memoria de replay con experiencias encontradas con acciones iniciales aleatorias. Es decir la poblaremos con muestras iniciales:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBUxhgSMRZxe",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "    # populate replay memory\n",
        "    if (train_or_test == 'train'):\n",
        "      print(\"populating replay memory\")\n",
        "      replay_memory = populate_replay_mem(sess, env, state_processor, replay_memory_init_size, policy, epsilon_start, \n",
        "                                                       epsilon_end[0], epsilon_decay_steps[0], VALID_ACTIONS, Transition)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "374EOXq2RZxf",
        "colab_type": "text"
      },
      "source": [
        "##### Set de los valores epsilon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG9GXLhSRZxf",
        "colab_type": "text"
      },
      "source": [
        "Ahora haremos el set de los valores `epsilon`. Nótese que tenemos una función lineal doble, la cuál hará decrecer el valor de `epsilon`, primero de $1$ a $0.1$, y luego de $0.1$ a $0.01$, en tantos pasos, como estén especificados en `epsilon_decay_steps`: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLEmbV3rRZxg",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "    # epsilon start\n",
        "    if (train_or_test == 'train'):\n",
        "       delta_epsilon1 = (epsilon_start - epsilon_end[0])/float(epsilon_decay_steps[0])     \n",
        "       delta_epsilon2 = (epsilon_end[0] - epsilon_end[1])/float(epsilon_decay_steps[1])    \n",
        "       if (train_from_scratch == True):\n",
        "          epsilon = epsilon_start\n",
        "       else:\n",
        "          if (start_iter <= epsilon_decay_steps[0]):\n",
        "             epsilon = max(epsilon_start - float(start_iter) * delta_epsilon1, epsilon_end[0])\n",
        "          elif (start_iter > epsilon_decay_steps[0] and start_iter < epsilon_decay_steps[0]+epsilon_decay_steps[1]):\n",
        "             epsilon = max(epsilon_end[0] - float(start_iter) * delta_epsilon2, epsilon_end[1])\n",
        "          else:\n",
        "             epsilon = epsilon_end[1]      \n",
        "    elif (train_or_test == 'test'):\n",
        "       epsilon = epsilon_end[1]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z6YVCODRZxg",
        "colab_type": "text"
      },
      "source": [
        "##### Set del número total de time steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-xMFoRlRZxh",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "    # total number of time steps \n",
        "    total_t = start_iter\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265nN5KPRZxh",
        "colab_type": "text"
      },
      "source": [
        "Luego, el loop principal inicia sobre los episodios, desde `start_episode` hasta el número total de episodios `num_episodes`.\n",
        "\n",
        "Primero hacemos el reset del episodio, procesamos el primer frame, y lo apilamos 4 veces. Luego inicializamos `loss`, `time_steps`, y `episode_rewards` a `0`.\n",
        "\n",
        "El número total de vidas en el juego Breakout por episodio son 5, y llevaremos cuenta de esto en la variable `ale_lives`. El número total de time steps en la vida actual del agente se inicializa con un número grande:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0OhDfdKRZxi",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "    for ep in range(start_episode, num_episodes):\n",
        "\n",
        "        # save ckpt\n",
        "        saver.save(tf.get_default_session(), checkpoint_path)\n",
        "\n",
        "        # env reset\n",
        "        state = env.reset()\n",
        "        state = state_processor.process(sess, state)\n",
        "        state = np.stack([state] * 4, axis=2)\n",
        "\n",
        "        loss = 0.0\n",
        "        time_steps = 0\n",
        "        episode_rewards = 0.0\n",
        "    \n",
        "        ale_lives = 5\n",
        "        info_ale_lives = ale_lives\n",
        "        steps_in_this_life = 1000000\n",
        "        num_no_ops_this_life = 0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71CzJtj-RZxj",
        "colab_type": "text"
      },
      "source": [
        "##### Tracking de los time steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKvhFZ1FRZxk",
        "colab_type": "text"
      },
      "source": [
        "Usaremos un `while` loop interno para hacer el track de los time steps dado un episodio. \n",
        "\n",
        "Nota: El `for` loop de afuera está sobre los episodios, en cambio el `while` loop de adentro está sobre los time steps del episodio actual.\n",
        "\n",
        "Haremos decrecer el valor de `epsilon` de acuerdo y dependiendo de si está en el rango $(0.1,1)$ o $(0.01,0.1)$, para los cuales se aplica un valor diferente de `delta_epsilon`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtix2aUmRZxl",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "    while True:\n",
        "            \n",
        "            if (train_or_test == 'train'):\n",
        "              #epsilon = max(epsilon - delta_epsilon, epsilon_end) \n",
        "              if (total_t <= epsilon_decay_steps[0]):\n",
        "                    epsilon = max(epsilon - delta_epsilon1, epsilon_end[0]) \n",
        "              elif (total_t >= epsilon_decay_steps[0] and total_t <= epsilon_decay_steps[0]+epsilon_decay_steps[1]):\n",
        "                    epsilon = epsilon_end[0] - (epsilon_end[0]-epsilon_end[1]) / float(epsilon_decay_steps[1]) * float(total_t-epsilon_decay_steps[0]) \n",
        "                    epsilon = max(epsilon, epsilon_end[1])           \n",
        "              else:\n",
        "                    epsilon = epsilon_end[1]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nzL6aQTRZxm",
        "colab_type": "text"
      },
      "source": [
        "##### Actualizando la red target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYf6lJdQRZxm",
        "colab_type": "text"
      },
      "source": [
        "Hacemos el update de la red target si el número total de time steps en el modelo es un múltiplo de `update_target_net_every`, el cuál es un parámetro definido por el usuario. Se usa también la función `copy_model_parameters()`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C_iuQBuRZxn",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "              # update target net\n",
        "              if total_t % update_target_net_every == 0:\n",
        "                 copy_model_parameters(sess, q_net, target_net)\n",
        "                 print(\"\\n copied params from Q net to target net \")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHkpHr4iRZxn",
        "colab_type": "text"
      },
      "source": [
        "En el comienzo de cada vida del agente, emprendemos por tomar la acción de **quedarse quieto** que corresponde a las probabilidades de acción $[1,0,0,0]$, un número aleatorio de veces entre 0 y 7 para hacer el episodio distinto a los pasados, para que el agente obtenga una mayor variación cuando explora y aprende del ambiente. Este paso de aletoriedad también se concibe en el paper donde se describe el algoritmo original de DeepMind, y nos asegura que el agente aprende mejor, ya que la aleatoriedad nos brinda mayor diversidad experimentada.\n",
        "\n",
        "Una vez terminamos este primer ciclo de aleatoriedad, las acciones se toman de acuerdo a la función `policy()`.\n",
        "\n",
        "Nótese que aún necesitamos tomar una acción de **disparar** que corresponde a las probabilidades de acción $[0,1,0,0]$, esto para un time step al inicio de cada vida con el fin de darle el puntapié de inicio a nuestro agente. Esto es un requerimiento para el framework ALE, sin el cuál los frames simplemente se congelarían. \n",
        "\n",
        "Así, el ciclo de vida evoluciona, empezando por una operación de disparo, seguido por un número aleatorio (entre 0 y 7) de **quedarse quieto**, y luego el agente usa la función `policy()`:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Aso44SMRZxo",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "            time_to_fire = False\n",
        "            if (time_steps == 0 or ale_lives != info_ale_lives):\n",
        "               # new game or new life \n",
        "               steps_in_this_life = 0\n",
        "               num_no_ops_this_life = np.random.randint(low=0,high=7)\n",
        "               action_probs = [0.0, 1.0, 0.0, 0.0]  # fire\n",
        "               time_to_fire = True\n",
        "               if (ale_lives != info_ale_lives):\n",
        "                  ale_lives = info_ale_lives\n",
        "            else:\n",
        "               action_probs = policy(sess, state, epsilon)\n",
        "\n",
        "            steps_in_this_life += 1 \n",
        "            if (steps_in_this_life < num_no_ops_this_life and not time_to_fire):\n",
        "               # no-op\n",
        "               action_probs = [1.0, 0.0, 0.0, 0.0] # no-op\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft7VUQolRZxo",
        "colab_type": "text"
      },
      "source": [
        "Ahora tomaremos una acción usando `np.random.choice`, que usará las probabilidades de `action_probs`. Luego renderizamos el ambiente y tomar un `step.info['ale.lives']` nos permitirá saber el número de vidas restantes del agente, de lo cuál podremos asegurar si el agente perdió una vida en el time step actual. \n",
        "\n",
        "En el paper de Deep Mind, las recompensas se establecieron como `+1` o `-1` dependiendo en la señal de recompensa, para ser comparables en diferentes juegos. Esto se logra usando `np.sign(reward)`, que no se usará aquí por ahora.\n",
        "\n",
        "Luego procesamos `next_state_image` para convertirla a una escala de grises del tamaño deseado, que luego se añade al vecotr `next_state`, que mantiene una secuencia de 4 frames contiguos. Las recompensas obtenidas se usan para incrementar `episode rewards`, y también incrementar `time_steps`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyih3goDRZxp",
        "colab_type": "text"
      },
      "source": [
        "```python            \n",
        "            action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "             \n",
        "            env.render()\n",
        "            next_state_img, reward, done, info = env.step(VALID_ACTIONS[action]) \n",
        "            \n",
        "            info_ale_lives = int(info['ale.lives'])\n",
        "\n",
        "            # rewards = -1,0,+1 as done in the paper\n",
        "            #reward = np.sign(reward)\n",
        "\n",
        "            next_state_img = state_processor.process(sess, next_state_img)\n",
        "\n",
        "            # state is of size [84,84,4]; next_state_img is of size[84,84]\n",
        "            #next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)\n",
        "            next_state = np.zeros((84,84,4),dtype=np.uint8)\n",
        "            next_state[:,:,0] = state[:,:,1] \n",
        "            next_state[:,:,1] = state[:,:,2]\n",
        "            next_state[:,:,2] = state[:,:,3]\n",
        "            next_state[:,:,3] = next_state_img    \n",
        "\n",
        "\n",
        "            episode_rewards += reward  \n",
        "            time_steps += 1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CEW5GYWRZxp",
        "colab_type": "text"
      },
      "source": [
        "##### Actualizando las redes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiVY2iH3RZxq",
        "colab_type": "text"
      },
      "source": [
        "Si estamos en modo de entrenamiento `'train'`, vamos a actualizar las redes. Primero sacamos el emento más antiguo en la memoria de replay si el tamaño se sobrepasa. Luego añadimos la tupla reciente `(state, action, reward, next_state, done)` a la memoria de replay. Nótese que si hemos perdido una vida, trataremos `done = True` en el último paso para que el agente aprenda a evitar perder vidas; sin esto, `done = True` se experimenta solo cuando el episodio termina, es decir, cuando todas las vidas se gastan. Por esto enfatizamos en que el agente se consciente de perder vidas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrYhKvsDRZxq",
        "colab_type": "text"
      },
      "source": [
        "##### Muestreando un mini-batch del replay buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmd5I-rZRZxr",
        "colab_type": "text"
      },
      "source": [
        "Ahora muestreamos un mini-batch del replay buffer de `batch_size`. Calculamos los valores $Q$ del siguiente estado (`q_values_next`) usando la red target, y la usamos para el calculo del valor $Q$ greedy, el cuál se usa para calcular el target ($y$ en la ecuación presentada anterior). Una vez cada cuatro pasos, actualizamos la red $Q$ usando `q_net.update()`; esta frecuencia de actualización es de una vez cada cuatro, que se conoce por su estabilidad:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbeagUZiRZxs",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "            if (train_or_test == 'train'):\n",
        "\n",
        "                # if replay memory is full, pop the first element\n",
        "                if len(replay_memory) == replay_memory_size:\n",
        "                    replay_memory.pop(0)\n",
        "\n",
        "                # save transition to replay memory\n",
        "                # done = True in replay memory for every loss of life \n",
        "                if (ale_lives == info_ale_lives):\n",
        "                   replay_memory.append(Transition(state, action, reward, next_state, done))   \n",
        "                else:\n",
        "                   #print('loss of life ')\n",
        "                   replay_memory.append(Transition(state, action, reward, next_state, True))               \n",
        "\n",
        "                # sample a minibatch from replay memory\n",
        "                samples = random.sample(replay_memory, batch_size)\n",
        "                states_batch, action_batch, reward_batch, next_states_batch, done_batch = map(np.array, zip(*samples))\n",
        "\n",
        "\n",
        "                # calculate q values and targets \n",
        "                q_values_next = target_net.predict(sess, next_states_batch)\n",
        "                greedy_q = np.amax(q_values_next, axis=1) \n",
        "                targets_batch = reward_batch + np.invert(done_batch).astype(np.float32) * gamma * greedy_q\n",
        "               \n",
        "\n",
        "                # update net \n",
        "                if (total_t % 4 == 0):\n",
        "                   states_batch = np.array(states_batch)\n",
        "                   loss = q_net.update(sess, states_batch, action_batch, targets_batch)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm6CPzB6RZxs",
        "colab_type": "text"
      },
      "source": [
        "Ahora salimos del `while` loop de adentro si  `done = True`, de otra manera, avanzamos al siguiente time step, donde el estado ahora será `new_state` del paso anterior. Podemos también printear en pantalla:\n",
        "- El número de episodio\n",
        "- Time steps para el episodio\n",
        "- La recompensa alcanzada por episodio\n",
        "- El `epsilon` actual\n",
        "- El tamaño del buffer al final del episodio\n",
        "\n",
        "Estos valores será útiles para el análisis posterior, así que los guardaremos en un archivo llamado `performance.txt`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsiAhxOZRZxt",
        "colab_type": "text"
      },
      "source": [
        "```python            \n",
        "            if done:\n",
        "                #print(\"done: \", done)\n",
        "                break\n",
        "\n",
        "            state = next_state\n",
        "            total_t += 1\n",
        "            \n",
        "\n",
        "        if (train_or_test == 'train'): \n",
        "           print('\\n Eisode: ', ep, '| time steps: ', time_steps, '| total episode reward: ', episode_rewards, '| total_t: ', total_t, '| epsilon: ', epsilon, '| replay mem size: ', len(replay_memory))\n",
        "        elif (train_or_test == 'test'):\n",
        "           print('\\n Eisode: ', ep, '| time steps: ', time_steps, '| total episode reward: ', episode_rewards, '| total_t: ', total_t, '| epsilon: ', epsilon)\n",
        "\n",
        "\n",
        "        if (train_or_test == 'train'):\n",
        "            f = open(\"experiments/\" + str(env.spec.id) + \"/performance.txt\", \"a+\")\n",
        "            f.write(str(ep) + \" \" + str(time_steps) + \" \" + str(episode_rewards) + \" \" + str(total_t) + \" \" + str(epsilon) + '\\n')  \n",
        "            f.close()\n",
        "```            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAGLrw1-RZxt",
        "colab_type": "text"
      },
      "source": [
        "#### Últimos detalles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAngYxADRZxt",
        "colab_type": "text"
      },
      "source": [
        "Reseteamos el grafo de TensorFLow para que empiece usando `tf.reset_default_graph()`. Entonces, creamos dos instancias de la clase `QNetwork()`, los objetos `q_net` y `target_net`. \n",
        "\n",
        "Creamos también un objeto `state_processor` de la clase `ImageProcess` y un objeto TensorFlow `saver`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-gWzFX7RZxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "\n",
        "# Q and target networks \n",
        "q_net = QNetwork(scope=\"q\",VALID_ACTIONS=VALID_ACTIONS)\n",
        "target_net = QNetwork(scope=\"target_q\", VALID_ACTIONS=VALID_ACTIONS)\n",
        "\n",
        "# state processor\n",
        "state_processor = ImageProcess()\n",
        "\n",
        "# tf saver\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2er7JsaaRZxy",
        "colab_type": "text"
      },
      "source": [
        "Ahora ejecutamos nuestro grafo de TensorFlow llamando `tf.Session()`. Si empezamos desde el inicio en modo `'train'`, tenemos que inicializar las variables, que se logra al llamar `sess.run()` en `tf.global_variables_initializer()`. \n",
        "\n",
        "De otra manera, si estamos en modo `'test'`, o en modo de entramiento pero no desde el inicio, cargamos el último checkpoint file al llamar `saver.restore()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnrMzBmFRZxz",
        "colab_type": "text"
      },
      "source": [
        "El parámetro `replay_memory_size` está limitado por la capacidad de almacenamiento en memoria RAM que se tenga disponible en la máquina. Las presentes simulaciones se realizaron usando una imagen de Ubuntu 18.04 corriendo en un hipervisor Virtual Box al cuál se le asignaron 10GB de RAM en un sistema local Windows 10, y  el límite era `replay_memory_size = 300000`.\n",
        "\n",
        "DeepMind usó un tamaño de memoria de replay de $1000000$. Un tamaño de memoria de replay grande es bueno ya que proveerá mayor diversidad en el entrenamiento al muestrear un mini-batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHHIG7C5RZx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        " \n",
        "      # load model/ initialize model\n",
        "      if ((train_or_test == 'train' and train_from_scratch == False) or train_or_test == 'test'):\n",
        "                 latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "                 print(\"loading model ckpt {}...\\n\".format(latest_checkpoint))\n",
        "                 saver.restore(sess, latest_checkpoint)\n",
        "      elif (train_or_test == 'train' and train_from_scratch == True):\n",
        "                 sess.run(tf.global_variables_initializer())    \n",
        "\n",
        "\n",
        "\n",
        "      # run\n",
        "      deep_q_learning(sess, env, q_net=q_net, target_net=target_net, state_processor=state_processor, num_episodes=25000,\n",
        "                            train_or_test=train_or_test, train_from_scratch=train_from_scratch, start_iter=start_iter, start_episode=start_episode,\n",
        "                                    replay_memory_size=300000, replay_memory_init_size=5000, update_target_net_every=10000,\n",
        "                                    gamma=0.99, epsilon_start=epsilon_start, epsilon_end=[0.1,0.01], epsilon_decay_steps=[1e6,1e6], batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}